{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.pipeline import Pipeline\n",
        "import warnings\n",
        "\n",
        "# Function to load the data\n",
        "def load_data(file_name):\n",
        "    data = pd.read_excel(file_name)\n",
        "    return data['ENGLISH'], data['HINDI']\n",
        "\n",
        "# Function to create Perceptron pipeline\n",
        "def create_perceptron_pipeline():\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    perceptron_model = Perceptron()\n",
        "\n",
        "    perceptron_pipeline = Pipeline([\n",
        "        ('tfidf', tfidf_vectorizer),\n",
        "        ('model', perceptron_model)\n",
        "    ])\n",
        "\n",
        "    return perceptron_pipeline\n",
        "\n",
        "# Function to create MLP pipeline\n",
        "def create_mlp_pipeline():\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    mlp_model = MLPClassifier(max_iter=200)  # Set max_iter to avoid convergence warnings\n",
        "\n",
        "    mlp_pipeline = Pipeline([\n",
        "        ('tfidf', tfidf_vectorizer),\n",
        "        ('model', mlp_model)\n",
        "    ])\n",
        "\n",
        "    return mlp_pipeline\n",
        "\n",
        "# Function to define the hyperparameter grid for Perceptron\n",
        "def get_perceptron_hyperparameters():\n",
        "    param_grid = {\n",
        "        'model__penalty': ['l2', 'elasticnet'],\n",
        "        'model__alpha': [0.0001, 0.001, 0.01],\n",
        "        'model__max_iter': [1000, 2000, 3000]\n",
        "    }\n",
        "    return param_grid\n",
        "\n",
        "# Function to define the hyperparameter grid for MLP\n",
        "def get_mlp_hyperparameters():\n",
        "    param_grid = {\n",
        "        'model__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
        "        'model__activation': ['tanh', 'relu'],\n",
        "        'model__solver': ['sgd', 'adam'],\n",
        "        'model__alpha': [0.0001, 0.001, 0.01],\n",
        "        'model__learning_rate': ['constant', 'adaptive']\n",
        "    }\n",
        "    return param_grid\n",
        "\n",
        "# Function to perform RandomizedSearchCV for hyperparameter tuning\n",
        "def tune_hyperparameters(pipeline, param_grid, X, y):\n",
        "    # Filter out classes with only one instance\n",
        "    y_counts = y.value_counts()\n",
        "    classes_to_keep = y_counts[y_counts > 1].index\n",
        "    X_filtered = X[y.isin(classes_to_keep)]\n",
        "    y_filtered = y[y.isin(classes_to_keep)]\n",
        "\n",
        "    # Using StratifiedKFold for cross-validation with fewer splits\n",
        "    stratified_kfold = StratifiedKFold(n_splits=2)\n",
        "    random_search = RandomizedSearchCV(pipeline, param_distributions=param_grid, n_iter=5, cv=stratified_kfold, n_jobs=-1, random_state=42)\n",
        "    random_search.fit(X_filtered, y_filtered)\n",
        "    return random_search.best_params_, random_search.best_score_\n",
        "\n",
        "# Main function to run the code\n",
        "def main():\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    file_name = 'Book1.xlsx'\n",
        "    english_text, hindi_text = load_data(file_name)\n",
        "\n",
        "\n",
        "\n",
        "    # Tune hyperparameters for Perceptron\n",
        "    perceptron_pipeline = create_perceptron_pipeline()\n",
        "    perceptron_params = get_perceptron_hyperparameters()\n",
        "    perceptron_best_params, perceptron_best_score = tune_hyperparameters(perceptron_pipeline, perceptron_params, english_text, hindi_text)\n",
        "    print(\"Best Perceptron Parameters:\", perceptron_best_params)\n",
        "    print(\"Best Perceptron Score:\", perceptron_best_score)\n",
        "\n",
        "    # Tune hyperparameters for MLP\n",
        "    mlp_pipeline = create_mlp_pipeline()\n",
        "    mlp_params = get_mlp_hyperparameters()\n",
        "    mlp_best_params, mlp_best_score = tune_hyperparameters(mlp_pipeline, mlp_params, english_text, hindi_text)\n",
        "    print(\"Best MLP Parameters:\", mlp_best_params)\n",
        "    print(\"Best MLP Score:\", mlp_best_score)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G61WiBjyOaRA",
        "outputId": "eebb5349-1ab5-4f3c-d11d-914c247de388"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Perceptron Parameters: {'model__penalty': 'l2', 'model__max_iter': 1000, 'model__alpha': 0.0001}\n",
            "Best Perceptron Score: 0.7\n",
            "Best MLP Parameters: {'model__solver': 'sgd', 'model__learning_rate': 'constant', 'model__hidden_layer_sizes': (100,), 'model__alpha': 0.0001, 'model__activation': 'tanh'}\n",
            "Best MLP Score: 0.03333333333333333\n"
          ]
        }
      ]
    }
  ]
}